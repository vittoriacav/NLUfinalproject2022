{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLUnotebook.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# **Natural Language Understanding Final Project**\n","### Maria Vittoria Cavicchioli (230483) - 29 July 2022\n","\n","**Description**: implementation of a Language Model using one of the RNN architectures (eg. Vanilla, LSTM, GRU)\n","\n","**Dataset**: Penn Treebank\n","\n","**Main reference papers**: \n","\n","- Zaremba, Wojciech, et al. _Recurrent Neural Network Regularization._ 1 Sept. 2014. NASA ADS, https://ui.adsabs.harvard.edu/abs/2014arXiv1409.2329Z.\n","\n","- Gal, Yarin, and Zoubin Ghahramani. _A Theoretically Grounded Application of Dropout in Recurrent Neural Networks._ arXiv:1512.05287, arXiv, 5 Oct. 2016. arXiv.org, http://arxiv.org/abs/1512.05287.\n","\n","**Acknowledgement**: since this is one of the first times I try to implement deep neural architectures I needed some help to get started. That's why I used some GitHub repositories to first understand the usage of the main functions. For some small parts of the code I also took inspiration from them but the majority of the code was developed by me. \n","\n","Here are the repositories that I investigated the most to understand things:\n","- [`floydhub/word-language-model`](https://github.com/floydhub/word-language-model/tree/19eac43f43bdb415aa8b23d9827ccd410f15e545)\n","- [`ahmetumutdurmus/zaremba`](https://github.com/ahmetumutdurmus/zaremba)\n","- [`wojzaremba/lstm`](https://github.com/ahmetumutdurmus/zaremba)\n","- [`PetrochukM/PyTorch-NLP`](https://github.com/PetrochukM/PyTorch-NLP)\n","\n","\n"],"metadata":{"id":"Qk5YeGhViddB"}},{"cell_type":"markdown","source":["I will use [PyTorch-NLP](https://pytorchnlp.readthedocs.io/en/latest/index.html) to retrieve and easily manipulate the Penn Treebank dataset. However, due to some lack of compatibility between the latest version of PyTorch (1.12.0+cu113) and PyTorch-NLP `BPTTBatchSampler`, I installed an older version of PyTorch (1.8.0+cu111).\n","\n","Sometimes at the end of the installation it is asked to restart runtime. After the restarting, the correct version of PyTorch will be there."],"metadata":{"id":"4lU6R1h3x9JC"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"K5Y0V75VxrCC"},"outputs":[],"source":["# Install Pytorch-NLP and the PyTorch version compatible with 'BPTTBatchSampler'\n","!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n","!pip install pytorch-nlp"]},{"cell_type":"code","source":["print(\"Importing required libraries...\")\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","\n","try:\n","    from torchnlp.datasets import penn_treebank_dataset  \n","    from torchnlp.samplers import BPTTBatchSampler\n","    from torchnlp.encoders import LabelEncoder\n","    from torchnlp.nn import LockedDropout\n","except:\n","    if torch.__version__ != \"1.8.0+cu111\":\n","        print(\"You don't have the correct version of PyTorch! Please install version 1.8.0+cu111 using commad above.\")\n","\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from collections import Counter\n","\n","\n","print(\"All packages correctly loaded!\")\n","\n","print(\"PyTorch version \", torch.__version__)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g0wjycY0yW8H","executionInfo":{"status":"ok","timestamp":1658501612691,"user_tz":-120,"elapsed":1412,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}},"outputId":"6d922db2-2ac5-4be1-c28d-fb02786e4fd3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Importing required libraries...\n","All packages correctly loaded!\n","PyTorch version  1.8.0+cu111\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# change the directory to the folder where the notebook is placed\n","%cd /content/drive/MyDrive/Colab Notebooks/NLUproj2022\n","! ls"],"metadata":{"id":"GjcXB7ip0N11","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1658501633568,"user_tz":-120,"elapsed":17475,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}},"outputId":"1d276896-88d8-4468-a07c-87abe144a58a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/10ntVgv5dvIM_diD5JVIcADDP01ojdp1j/NLUproj2022\n","data  NLUnotebook.ipynb  trained_models\n"]}]},{"cell_type":"markdown","source":["## **Dataset Analysis**\n","I now load and analyze the Penn Treebank dataset [[1](https://aclanthology.org/J93-2004/)]"],"metadata":{"id":"8ulxH5CL2MwF"}},{"cell_type":"code","source":["# (PyTorch-NLP) 'penn_treebank_dataset' loads the Penn Treebank Project: \n","# Release 2 CDROM, featuring a million words of 1989 Wall Street Journal material.\n","\n","train, val, test = penn_treebank_dataset(train=True, dev = True, test = True)\n","\n","corpus = train + val + test\n","# (PyTorch-NLP) 'LabelEncoder' encodes labels via dictionary. It will contain the \n","# vocabulary and useful methods to convert text into labels and vice versa\n","\n","encoder = LabelEncoder(train, reserved_labels=[])\n","\n","\n","print(\"\\nThe vocabulary size of the PTB corpus is \", encoder.vocab_size)\n","print(\"Train set size is {:d} | Validation set size is {:d} | Testing set size is {:d}\".format(\n","    len(train), len(val), len(test)\n","    ))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4F5pMj62MEW","executionInfo":{"status":"ok","timestamp":1658505951830,"user_tz":-120,"elapsed":357,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}},"outputId":"fc2d4703-1ba8-4e4d-c8d5-257ad1031906"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","The vocabulary size of the PTB corpus is  10000\n","Train set size is 929589 | Validation set size is 73760 | Testing set size is 82430\n"]}]},{"cell_type":"code","source":["sents_len = np.empty([0])\n","counter = 0\n","\n","for i in corpus:\n","    if i != \"</s>\":\n","        counter += 1\n","    else:\n","        counter += 1\n","        sents_len = np.append(sents_len, counter)\n","        counter = 0\n","\n","avg_sent_len = np.mean(sents_len)\n","print(\"The average words per sentence are: {:.3f}\".format(avg_sent_len))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t5QT7uzjXkNF","executionInfo":{"status":"ok","timestamp":1658505970496,"user_tz":-120,"elapsed":1521,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}},"outputId":"2b5152af-8d7b-4100-f04e-8a42be12a30c"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["The average words per sentence are: 22.069\n"]}]},{"cell_type":"markdown","source":["A random example taken from the training PTB set shows us that sentences are already heavily pre-processed."],"metadata":{"id":"EixxTm0B6LhU"}},{"cell_type":"code","source":["\" \".join(train[41:53])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"4p76lgyZ5Rox","executionInfo":{"status":"ok","timestamp":1658505985306,"user_tz":-120,"elapsed":301,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}},"outputId":"b4873c55-b30a-45ec-c65a-7f18513e2f0d"},"execution_count":49,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'mr. <unk> is chairman of <unk> n.v. the dutch publishing group </s>'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["We also verify if Zipf's Law holds:\n","\n","$k \\approx r \\cdot n$\n","\n","Where $k$ is a constant, $n$ is the word frequency inside the corpus and $r$ is the word rank."],"metadata":{"id":"jYb2ve_q65lk"}},{"cell_type":"code","source":["# we first remove the symbols used for processing the corpus \n","train_clean = [word for word in train if word != \"</s>\" and word != \"<unk>\" and word != \"N\" and word != \"$\"]\n","val_clean = [word for word in val if word != \"</s>\" and word != \"<unk>\" and word != \"N\" and word != \"$\"]\n","test_clean = [word for word in test if word != \"</s>\" and word != \"<unk>\" and word != \"N\" and word != \"$\"]\n","\n","corpus_clean = train_clean + val_clean + test_clean"],"metadata":{"id":"rUhNUglO83SR","executionInfo":{"status":"ok","timestamp":1658506048295,"user_tz":-120,"elapsed":647,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["freq_list = Counter(corpus_clean)\n","\n","x = []\n","y = []\n","k_all = np.empty(len(freq_list))\n","\n","display = 10\n","print(\"|Rank|Freq|Word|\")\n","print(\"================\")\n","for i, word in enumerate(freq_list.most_common(len(freq_list))):\n","    x.append(i+1)\n","    y.append(word[1]/len(corpus))\n","    k_all[i] = (i+1)*(word[1]/len(corpus))\n","    if display > 0:\n","        print(\"|{:d}|{:d}|{}|\".format(i+1, word[1], word[0]))\n","        display -= 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IDffAjEL626k","executionInfo":{"status":"ok","timestamp":1658506080988,"user_tz":-120,"elapsed":262,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}},"outputId":"2315b9b0-6e85-48ea-e1e3-1c61eb23f14d"},"execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":["|Rank|Freq|Word|\n","================\n","|1|59421|the|\n","|2|28427|of|\n","|3|27430|to|\n","|4|24755|a|\n","|5|21032|in|\n","|6|20404|and|\n","|7|11555|'s|\n","|8|10436|for|\n","|9|10419|that|\n","|10|8533|is|\n"]}]},{"cell_type":"code","source":["k = np.mean(k_all)\n","\n","# we create a reference\n","r = np.linspace(1,len(x),len(x)*10)\n","n = k/r\n","\n","plt.plot(np.log(x),np.log(y), label = \"PTB\")\n","plt.plot(np.log(r),np.log(n), label = \"reference\")\n","plt.xlabel('ln ( frequency rank )')\n","plt.ylabel('ln ( frequency )')\n","plt.legend()\n","\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"gHFrVED_9rU5","executionInfo":{"status":"ok","timestamp":1658506150714,"user_tz":-120,"elapsed":813,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}},"outputId":"2dd408b7-7bdd-417a-875a-70920eaa7aad"},"execution_count":53,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYcAAAEGCAYAAACO8lkDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3RUVdfH8e9ODyQQCAktBIJAAOmELr0XGzaQR0QFRAGxIogFFTuIjyAi+qKgiKBYQXrvEHqXDqGGEkKA9PP+cQceNCEGMsmdJPuzVpaZmTN3fjNLsuecc+85YoxBKaWUup6b3QGUUkq5Hi0OSiml0tDioJRSKg0tDkoppdLQ4qCUUioND7sDOEOxYsVMuXLl7I6hlFK5yoYNG84YY4LSeyxPFIdy5coRGRlpdwyllMpVROTwjR7TYSWllFJpaHFQSimVhhYHpZRSaeSJOQelVN6TlJREVFQU8fHxdkfJ9Xx8fAgJCcHT0zPTz9HioJRySVFRUfj7+1OuXDlExO44uZYxhrNnzxIVFUVYWFimn6fDSkoplxQfH09gYKAWhiwSEQIDA2+6B6bFQSnlsrQwOMetfI75uzgkxcOfgyH2uN1JlFLKpeTvOYdjG2DjJNg8BVoMhQb9wD1/fyRKqf9xd3enevXqJCcnU6VKFT755BM6d+4MwMmTJ3F3dycoyLrAeN26dfj6+lK9enWMMbi7uzN27FgaN25s51u4Zfn7L2G5JvD0GvjzJZg3DLZMhc4fQ2gDu5MppVyAr68vmzdvBqBHjx5Mmzbt2u3hw4fj5+fHiy++mG77uXPnMnToUJYuXZrzwZ0gfw8rARQNgx4/woPfwpXzMLEd/D4QLp+zO5lSyoU0bdqUffv2Zbp9bGwsRYoUycZE2St/9xyuEoGqd8FtrWDJe7Dmc9g1E9q+BbV6gJvWUKXs9OYfO9h5PNapx6xaqhBv3Hl7ptomJycze/ZsOnTokGG7K1euUKtWLeLj4zlx4gSLFi1yRlRb6F+963n7Qft3oN9yKFYJfh8AX3eEUzvsTqaUssHVP/YRERGEhobyxBNPZNj+6rDS7t27mTNnDj179sQYk0NpnUt7Dukpfjs8Nhu2fA/zXoPxTaHhU9BiCHj7251OqXwns9/wne36OYSb1ahRI86cOUN0dDTBwcFOTpb9tOdwI25uUPs/MHAD1O4Bq8fC2Pqw8zfIpd8ElFI5Z/fu3aSkpBAYGGh3lFuSr4tDXEIyA6du4kB03I0bFSgKd42Bx+dZv0/vCVMegHMHcy6oUipXuDoMVatWLR566CEmTZqEu7u73bFuSb4eVtpz8iJL95xm7o6TPNemEn2ahuHhfoN6GdoA+i6FdV/A4ndhXENo+gI0GQQe3jkbXCmVI+LibvzFcfjw4WnuS0lJycY0OStf9xzqli3Cgueb0zI8iA/m7OaecSszPiPC3QMa9YcB66FSB1j8DnzeGPYvzrnQSimVA/J1cQAILuTD+P/U5bOH63DyQjx3jV3BqHl7SEjO4BtAoVLw4CToMQNSU+Dbe+Cnx+HiyZwLrpRS2SjfFwewFqXqXKMk859rzl21SjFm0T46f7qCjUfOZ/zEim3g6dXQfAjs+gPG1oO1X1gFQymlcjEtDtcpUtCLjx+sxdeP1eNyQjL3fb6Kt/7YyeXE5Bs/ydMXWg61luEoXRdmD4YJLSBqQ47lVkopZ9PikI6W4cHMfa4ZPRqEMnHlQdp/soyV+85k/KTA2+CRX+D+ryHuNHzVGv541lqSQymlchktDjfg7+PJiHuqM61vQ9xF6PHVWobM2MqFK0k3fpIIVOtqTVg3fMpa8XVMBGyeqtdGKKVyFS0O/6JB+UDmPNuMJ5uXZ3rkUdqNXsr8nacyfpJPIejwnnXqa9Ew+LUffNMZTu/KmdBKqRz16aefUqVKFXr06GF3FKfR4pAJPp7uDO1YhV/7N6FIAS/6TI5k4NRNnI1LyPiJJWtYF891+cRan2n8HTD/DUi8lDPBlVJOY4whNTU13cfGjRvH/PnzmTJlSqaOlZycwTymi9DicBNqhATw+4A7eK5NJeZsP0Gbj5fy2+ZjGS+s5eYGEY9Zy3DUeAhWfgKfNYDds3IuuFLqlhw6dIjw8HB69uxJtWrVePvtt6lXrx41atTgjTfeAKBfv34cOHCAjh07Mnr0aC5dusTjjz9O/fr1qV27Nr/99hsA33zzDXfddRetWrWidevWGbbr2rUrHTp0oGLFigwePPhanjlz5lCnTh1q1qxJ69atAW54nKzK11dI3wovDzcGtalIx+oleOmnrQz6YTO/bz7OiHurUbKw742fWLAY3DPOWq9p5vPww8NQqSN0/ACKlM25N6BUbjR7CJzc5txjlqgOHd//12Z79+5l0qRJxMbG8tNPP7Fu3TqMMdx1110sW7aM8ePHM2fOHBYvXkyxYsV45ZVXaNWqFRMnTiQmJob69evTpk0bADZu3MjWrVspWrRohu02b97Mpk2b8Pb2Jjw8nIEDB+Lj40OfPn1YtmwZYWFhnDtn7TnzzjvvpHucggULZunj0Z7DLapU3J+fn2rMq52rsHL/Gdp9vIzv1x759+V5yza2lgRv+xYcXGr1IpaPguTEnAmulLopZcuWpWHDhsybN4958+ZRu3Zt6tSpw+7du9m7d2+a9vPmzeP999+nVq1atGjRgvj4eI4cOQJA27ZtKVq06L+2a926NYULF8bHx4eqVaty+PBh1qxZQ7NmzQgLCwPI1HGyQnsOWeDuJvRuWp62VYszZMY2XvllG39sOc7791WnbGAGVdvd01qT6fauMGcILHwLtkyDzqMgrGnOvQGlcotMfMPPLle/gRtjGDp0KE8++WSG7Y0xzJgxg/Dw8L/dv3bt2r99m8+onbf3/9Zrc3d3z3CO4kbHySrtOThB2cCCfN+nAe91rc72Yxdo/8kyvlp+gJTUf+lFBJSBblPg4emQfAUmdYGf+1rXSSilXEr79u2ZOHHitcX4jh07xunTaf+ttm/fnjFjxlwbRdi0adMNj5eZdlc1bNiQZcuWcfCgtSL01WGlmz1OZmnPwUlEhO71Q2kRHsSrv2xnxKxdzNh4jKolC+Hn7Y6fjwd+3p74+Xjg7+1BQW8P/Lw98PfxwK/oHRTsuYwiG8bgvvpTZM8caP0aRDwObrlzuV+l8pp27dqxa9cuGjVqBICfnx/fffddmo18XnvtNZ599llq1KhBamoqYWFhzJw5M83xMtvuqqCgICZMmEDXrl1JTU0lODiY+fPn3/RxMkty6xZ214uIiDCRkZF2x7jGGMPvW44zYdkBYi4nEZeQTFxC8r/3JIBKbsf5wHcytVO2crZwNWJbf0BotSa4u0kOJFfKdezatYsqVarYHSPPSO/zFJENxpiI9NprzyEbiAh31yrN3bVKX7vPGEN8UioXE5KIi0/mUkLKtd+vFo+4hGRir9zG2JM1KX5kJs/FfEPojC78MKMdi0r2JbxcCLVDi1CrTABB/rqHhFIq+2hxyCEigq+XO75e7gRnYhtqY+px9EQ/Ds9/m+4Hp9Lp1FreivoP45IbAUJYsYL0aBDKQ/XK4O/jme35lVL5i05IuygRIbRUKco/+jlufRdTpGQYoz3GsjXsMz5s7kOQnzcjZu2i0XuLGDFzJ1HnL9sdWSmnywvD3q7gVj5Hly0OIvKCiBgRKWZ3FtuVqg29F0LnURQ6t4MH1z/E9IoL+KNfHVpVDubrVYdo/tESBny/kc1HY+xOq5RT+Pj4cPbsWS0QWWSM4ezZs/j4+NzU81xyQlpEygBfAZWBusaYDNfLdrUJ6WwVdxrmvQpbp0FAKHQayfHgZkxadYjv1x3hYnwyEWWL0LB8IMUL+1Dc35vihXwoXsiHYn5eN94jWykXk5SURFRUFPHx8XZHyfV8fHwICQnB0/PvQ9AZTUi7anH4CXgb+A2I0OKQjoPLYdYLcGYPVO4CHT8gzqcE09cf5bu1hzl89nKas6M83IQP7qvBfXVDbAqtlHIluao4iMjdQCtjzCAROcQNioOI9AX6AoSGhtY9fPhwzgZ1BcmJsHoMLP0IxA1avAwNnwZ3T1JSDWfjEjgVm8Cp2HhOXYznuzVHuHA5kWWDW2oPQinlesVBRBYAJdJ5aBjwCtDOGHMho+JwvXzZc7je+cMw+2X4azYEVYEuH1trOP3D/J2n6DM5kjHda3NnzVI2BFVKuZKMioMtXx+NMW2MMdX++QMcAMKALY7CEAJsFJH0Com6qkhZePgH6PY9JMbB1x3h16fh0t9rauvKwZQLLMBXKw7qJJ9SKkMuNbZgjNlmjAk2xpQzxpQDooA6xpiTNkfLHSp3hv5rocmz1oT1mLqw4RtwbFDi5iY8fkcYW47GsPGI7m2tlLoxlyoOygm8CkLbN6HfCih+O/wxCCa2gxNbAbivTgiFfDz4vxUHbQ6qlHJlLl0cHD2IDOcb1A0EV4Fes+Ce8XDuIExoDrOHUNBcpnuDUOZsP8nRc3rhnFIqfS5dHFQWiUCt7jAwEur2grXj4bP69AvcgpvAN6sO2Z1QKeWitDjkB75FoMto6L0ACgZR5M8n+SNgNKvXr+NifJLd6ZRSLkiLQ34SEgF9FkPHD6mUtJtfeJG904ZBkl6BqpT6Oy0O+Y27BzR4EvdnIlnv24Q6B7/AjGsI+xbYnUwp5UK0OORX/iWI6zKeHolDuZho4Lv7YPqjEHvc7mRKKRegxSEfa1u1BGeDGxNx9k2mFHiElN2zMWPrwerPIOXGG5orpfI+l1tb6Vbk++UzsiA+KYUfN0Tx5bIDmPMHGVngOxqkbOCcfziR1V7lfNFahJcoRK0yAXZHVUo5mcutreRsWhyyLjklldnbT/L54n2Enl7IG56TKSnnmJrckpGp3fm4VyuaVwqyO6ZSyom0OKhMM8Zw7lIiqQkXKbBqJAU2TiCWAoxM7cHDTw6lSintQSiVV7jcwnvKdYkIgX7eBAUWo+Cd7yP9luNbsgpvy3gSv2zP2f0b7Y6olMoBWhxUxorfjlfvuUQ1+4jQ1GMEfNuaxNnDICHO7mRKqWykxUH9Ozc3Qlr1ZXvXhfyY0hyvtWMxn9WDnb9DHhiWVEqlpcVBZVrTmuFw56d0TRjO8QRfmP4IfP+gtbCfUipP0eKgbkq3+qG0bncnzS4MZ27IM5jDq2BcQ2ur0uQEu+MppZxEi4O6aU+3uI1HGt/Gk/sa8oD7Jyx3i4DFI4gdXZ+UfUvsjqeUcgI9lVXdktRUw+dL97P75EUuJSRT4vRy+saNp5zbKU6XvZPg+0eCv+7uqpQr0+scVLYzxjB3yyFOznqP7okzcPP0wbPt61CvN7i52x1PKZUOvc5BZTsRoUOtMLoN/pwXio1nbWIYzB4ME1pA1Aa74ymlbpIWB+VUPp7uvPnYXbxS8C2GuD3PlfMnMF+15uy0/uw5dISzcTpprVRu4GF3AJX3BPp5M/Gx+jz4RQozL1TleY+feHTnFMzO33kvpQfU6EbPxuWoVNwfH08dclLKFemcg8o28UkpRJ2/wumL8cjJbVTe8AZFzm1hnanCK4mPcYAQAv288ff2oGud0vRvWQERsTu2UvmGTkgr15CaChsnkbpgOCTEEVnqYf4I+A/7Ywyr9p/l/roh/KdhWSoE++HnrZ1apbKbFgflWi6dgfmvw+YpUDgU0/F9Pjlakf8u3AtAkQKefNkzgohyRW0OqlTepsVBuabDq2Dm8xC9Cyp15GjD4ey8EsD7s3dzLOYKdUIDCPD1onxQQXo3LU/Rgl52J1YqT9FTWZVrKtsY+i2Htm/BwaWU+b4F7c99z899I7izRilSDew9fZEvlh2g58S1nL+UaHdipfIN7Tko1xBzFOYMgd0zoVg4dB4FYU0BWLz7NH0mR5KcaggtWoAX24dTu0wAwYW88fbQs52UulU6rKRyjz1zYPZLEHMEanSDdm+DXzAbj5xnzYGz/LHlBLtOxF5r3r1+KCPuqYa7m57lpNTNuuXiICIhQDegKVAKuAJsB2YBs40xqc6Pe/O0OOQxiZdh+ShY+V/wKgCtX4e6j4GbO8kpqaw+cJYTMfFsOhrD1HVHKFXYh4fqhTKoTUW7kyuVq9xScRCRr4HSwEwgEjgN+ACVgJZAXWCIMWZZdoS+GVoc8qjov2DW83BoOZSqA11GQ6laf2vyY+RRJq0+xN5TcUS+2gZ/H097siqVC91qcahmjNmewUG9gFBjzD7nxLx1WhzyMGNg208w9xW4fMZayK/Vq+BT+FqTDYfPc9/nqxj1QE3uqxtiY1ilcpdbOlspo8LgeDzRFQqDyuNEoMYDMGC9VRjWfQljImDrj9e2KK0TGkBIEV++XH6Afacv2hxYqbxBT2VVuYNvAHT6CPouhsKl4efeMPluOLMXEeGVTlU4dv4K7T9Zzpt/7CAx2SWmw5TKtVyyOIjIQBHZLSI7RORDu/MoF1KqNvReaJ3qenwzfN4YFo2gU+UAlg5uSff6Zfh65SG6f7mG07HxdqdVKtf611NZRaS6MWZbDuVBRFoCw4DOxpgEEQk2xpzO6Dk655BPxZ2Gea/C1mkQUBY6jYRK7Zi59Tgv/bgVfx8PHm1cjhbhQdxeqvC/H0+pfCZL1zmIyHLAG/gGmGKMueD0hH9/venABGPMgsw+R4tDPndwGcx6Ac78BZW7QMcP2H2lEE9P2ciB6EsAlA0sQNsqxXmlUxXc9JoIpQAnXAQnIhWBx4EHgHXA18aY+U5N+b/X2gz8BnQA4oEXjTHr02nXF+gLEBoaWvfw4cPZEUflFsmJsHoMLP0IxA1aDME06EdMAszYGMWKfWdYsidaz2hS6jpOuUJaRNyBe4BPgVhAgFeMMT/fQqAFQHq7zw8D3gEWA88A9YBpQHmTQVDtOahrzh+G2S/DX7MhuCp0/hjKNiI11XDvuJVsO3aBaqULM+qBmlQs7m93WqVslaWF90SkhoiMBnYBrYA7jTFVHL+PvpVAxpg2xphq6fz8BkQBPxvLOiAVKHYrr6PyoSJl4eEfoNv3kHARvu4Av/bH7cpZJvaqx9MtKrA16sK15cGVUunLzNlKY4CNQE1jTH9jzEYAY8xx4NVsyPQr1hXYiEglwAs4kw2vo/Kyyp2h/1po8ixs/QHGRhC4Zyovtq1In6ZhzN5+ko/n7WFb1AXywvpiSjlbZiak/YArxpgUx203wMcYczlbAllXXk8EagGJWHMOizJ6jg4rqQyd3mVNWB9eCSH1uNjmQ55emMTyvdZ3jvDi/txTuzT1w4pQt6xuMKTyj6yerbQGaGOMiXPc9gPmGWMaOz3pLdLioP6VMbDlB+vU1yvnoEE/ztZ/kfn7LjFx5UH+OhUHQJMKgTxxRxgtKgXrWU0qz8tqcdhsjKn1b/fZSYuDyrTL52DR2xD5NfiXgPbvwu33ciE+mRkbohi3ZB9n4hJ5tFFZht91OyJaIFTeldWd4C6JSJ3rDlYXa+lupXKfAkWt1V17L4CCQfDTY/BdVwpfPsLjd4Sx4uVWPNqoLJNWH6bbhDXEJ6XYnVgpW2SmODwL/Cgiy0VkBdappQOyN5ZS2SwkAvoshg4fwNH1MK4RLH4PH5J4487b6dM0jLUHzzFx5UG7kypli8xeBOcJhDtu7jHGJGVrqpukw0oqSy6etJYE3z4DipaHTiMxt7Wiz+RIFuw6zdxnmxFeQq+JUHlPVoeVwLoYrQZQB+guIj2dFU4p2/mXgPsnwiO/WldXf9cV+bEXH7ULwtNd+HzJPlJS9XRXlb9kZkL6W+A2YDNwdQDWGGOeyeZsmaY9B+U0yQnW9qTLRoK7JwtK9ObJv+pSrFABqpcuTPf6oTSpUAwfT3e7kyqVZVk9W2kXUDWj5SvspsVBOd25A/DnYNg3nwuFK/N1wEB+OFGSk7Hx+Hl7MKBVBR6KKEORgl52J1XqlmV1WGk76a+DpFTeVbQ89PgRHpxM4dRYnj3cn5VVf+XrB8tTrlgB3p+9mzoj5nPPZys5FqMn76m8JzM9h8VYVyuvAxKu3m+MuSt7o2We9hxUtkq4CEvehzWfWzvStX2L7UGdWbznDJ8t2Udo0QJ82r02lUsUsjupUjclq8NKzdO73xiz1AnZnEKLg8oRJ7fDrOfh6FoIbQSdRzEnOpAhP2/Fz9uDPwbcocNMKlfJ0rCSowgcAjwdv6/HWohPqfylRDV4bA7cNRai98D4pnQ4PpanG5cg6vwVmn64mOG/72DjkfO6mJ/K9TLTc+iDtalOUWPMbY6Nf8YbY1rnRMDM0J6DynGXz8GCN2DjZChUmiMNXufd/RWYv/s0KamG0gG+fNkzgqqldKhJua6sTkj3B5pgbfCDMWYvEOy8eErlQgWKwl1j4PF54FuE0PlPMt79AzYNqMCoB2oSHZdAr6/XsXxvNKl6jYTKhTJTHBKMMYlXb4iIB6D/tysFENoA+i61FvA7vIpCE5tyX9xUnr4jhLOXEnnk/9bRfORiFuw8ZXdSpW5KZorDUhF5BfAVkbbAj8Af2RtLqVzE3QMa9Yf+66BSe1g8gmf3PsbWnt6817U6nu5u9J4cSfcJa1iy57TOR6hcITNzDm7AE0A7rH2j5wJfudJFcTrnoFzK3gXw54tw/iBUu5/41m/z7bZ4/m/FQU7GxtO2anEmPFJXlwNXtsvSqay5gRYH5XKSrsCK0daPhw+0eo3E2o8xcsE+Jiw7QKPygbSuEky3+qH4eXvYnVblU1m9zuEg6cwxGGPKOyde1mlxUC7r7H5ri9IDi6FkTUzn0Uw8VJRvVh3k6LkrVC9dmO/7NMDfx9PupCofympxCLzupg/wANZpra87L2LWaHFQLs0Y2PELzBkKcacg4nFo/RpjVp1h1Py/CPL35j8NyvJUi9vw8sjsQslKZZ3Th5UcB6yb5WROosVB5QrxsbD4XVj3BRQIhHYjmOvenG/XHGHFvjOEFPHl3tqlaVOlODVCCuuchMp2We051LnuphsQATxljKnpvIhZo8VB5SontsDM5+FYJJS9AzqPYmlMIOMW7yPy8HlSUg3F/LwZ2rEy99UNsTutysOyWhwWX3czGWspjZHGmD1OS5hFWhxUrpOaChsnwYLhkBgHjQdCs8GcT/Jg0e7T/HfhXo6cu0y7qsV5uWNlbgvyszuxyoP0bCWlXNWlMzD/ddg8BQqHQscPoHInTsXGM+yXbSzYdZqCXu78NuAOKgRrgVDOldWew/MZPW6M+TgL2ZxCi4PK9Q6vsoaaondBeCerSASEsuHweR6duI7k1FQGtqrIo43L6amvymmyurZSBPAUUNrx0w9rL2l/x49SKqvKNoZ+y6HtW3BgCYytD8s/pm7pgsx9rhl1yxbho7l7uOODRYxZuJfTsfF2J1Z5XGZ6DsuAzsaYi47b/sAsY0yzHMiXKdpzUHlKzFGYMwR2z4SgytB5FKZsEzYeOc/YRftYvCcadzehQ7USDGpdkUrF9TuaujVZHVbaA9QwxiQ4bnsDW40x4U5Peou0OKg8ac8cmP0SxByBGt2g3QjwC+LQmUtMWXuYyasPk5CcSu3QAL54pC7B/j52J1a5TFaLwzDgQeAXx133ANONMe86NWUWaHFQeVbiZVg+Clb+F7wKQOs3oG4vcHPnbFwC0yOjGDlvD8X8vPjw/po0q1hMr49QmZbls5Uc1zo0ddxcZozZ5MR8WabFQeV50X9ZW5QeWg6l60Lnj6FULQC2HI3huembORB9idCiBWheKYiO1UvQICwQdzctFOrGnFEc7gAqGmO+FpEgwM8Yc9DJOW+ZFgeVLxgD236EucPg8hmo1xtavQo+hbmSmMKvm4+xaPdpFu8+TXKqoVxgAR5tXI7HmoTZnVy5qKwOK72BdcZSuDGmkoiUAn40xjRxftRbo8VB5StXYmDRCFj/FfgFWxsNVbsPHMNJF64ksWTPab5ZdYhNR2JoXTmYF9uHU6Wkblmq/i6rxWEzUBvYaIyp7bhvqzGmhtOTWseuBYzHWuQvGXjaGLMuo+docVD50vFNMPM5679hzaHzKChW8drDKamG8Uv388XS/cTGJ1M7NIBmFYPo1bgcRQp62RhcuYqsFod1xpj6IrLRGFNHRAoCq7OxOMwDRhtjZotIJ2CwMaZFRs/R4qDyrdQUiJwIC9+G5CvQZBA0fQE8fa81uXA5ie/WHmbezlNsjYrBy92NOyoU4+mWFahbtoiN4ZXdsnoR3HQR+QIIEJE+wALgS2cG/AcDXO3/FgaOZ+NrKZW7ublD/T4wMBJuvxeWfQSfNYC/5l1rUriAJ/1bVuC3/k2Y92wzHowow4Yj53lg/Cre/GMHZ+MSbHwDylVl2HMQ65y4EKAy120TaoyZn22BRKpgbUUqWMWrsTHmcDrt+gJ9AUJDQ+sePpymiVL5z8Fl1uZCZ/6CKndCh/ehcNqVXWPjk3jjtx38sukYXh5uPFw/lD7NylM6wDedg6q8KqvDStuMMdWdHGgBUCKdh4YBrYGlxpgZIvIg0NcY0yaj4+mwklLXSU6E1WNg6UcgbtBiCDR8CtzT7ja3/dgFJq8+xIyNx/DxcKN30/L0aVZe12/KJ7JaHCYBY40x67MjXDqvdwEIMMYYR8/lgjEmw9MstDgolY7zh2D2y/DXHAiuCl1GQ2jDdJsePnuJl2dsZc2BcxTz8+KNO2/nzpqlcjavynFZnXNoAKwWkf0islVEtonIVudG/JvjQHPH762Avdn4WkrlXUXKwcPToNv3kHARJraHX/vDpbNpmpYNLMjUPg357okGFC/kw8Cpm3hv9i4SklNyPrdyCTfsOYhImDHmoIiUTe/x9OYBnBLIuuDuv4AHEI91KuuGjJ6jPQel/kXiJVj6IaweC97+0OZNqP0IuKX9fnjhShIvTN/Cgl2nKFnYhwfqhtCnWXn8fdIOS6nc7ZaGla7uEy0iC40xrbM1YRZpcVAqk07vsiasD6+EkPrQ5WMokf6U4qLdp/hm1WGW/RVN6QBfPn6wJvXDiuraTXnIrRaHTcCPWHs5jP7n466wyc9VWhyUugnGwJYfYN6rcOU8NOgHLYdaPYp0rN5/lmd+2ET0xQTqli1Cn6ZhtKlSHA/3zIxKK1d2q3MO3YAUrOEd/3R+lFK5kQjU6g4D1kOdnrBmHIytB5deZOwAABblSURBVDt+sQrHPzS6LZD5zzXj9S5VORUbT7/vNtL646VsORpjQ3iVUzJztlJHY8zsHMpzS7TnoFQWREVay3Cc3Aq3tYZOH0Hgbek2TUxOZXrkUd79cxfxSSk8GFGGF9uHU8zPO4dDK2fI8qqsrk6Lg1JZlJJsLeS3aASkJELT56HJs+CZ/gZCMZcTee/P3UzfcBRvDzcebVyO/zQoS5miBXI4uMoKLQ5Kqcy5eBLmvgLbZ0DR8tBpJFS48fkoe05e5NOFe5m17QR+3h68f191OlcvqZPWuURWr3NQSuUX/iXg/onwyC+AwHdd4cdeEJv+EmfhJfz5rEcdZg68g2B/bwZ8v4mBUzdx+mJ8jsZWznfD4uC43uCGRKSQiFRzfiSllO1uawVPr4aWw2D3nzC2PqweZw0/paNa6cLMfa4ZTzYrz8ytJ7jjg8VMWnUoZzMrp8roVNbRWFdHzwE2ANFYeyxUAFoCZYEXcmpZjYzosJJS2ejcAfjzJdi3wLomovNoKFPvhs33nY5jxKydLNkTTZ3QAIZ1rqpLg7uoW55zEJGiwH1AE6AkcAXYBcwyxqzIhqy3RIuDUtnMGNj1O8weAhePQ51Hoc1wKFA03eYpqYYvlu3n04V7iU9KpWvt0gzuUJkShdOf4Fb20AlppZRzJFyEJe/Dms/BNwDavg21Hr62Rek/nYlL4L0/dzNjYxTeHm4MaFmBXk3K6VIcLkKLg1LKuU5uh1nPw9G1ENoIOn8MxavesPnmozEM+mETh89eprCvJ+/cW40uNXTVV7tpcVBKOV9qKmyeAvNfh/gL0OhpaD4EvP3SbW6M4Y+tJxj++w7OXUokvLg/ox6sSbXShXM4uLpKi4NSKvtcPgcL3oCNk6FQCHR8Hyp3ueFQ0+XEZMYvPcDYRXtJNdCrcTmea1OJwgV0qCmnZbk4iEhjoBzWOksAGGMmOytgVmlxUMoFHFlrDTWd2g4V20PHD6Bo2A2bH4u5Qt/Jkew4HkvxQt5M6d2ACsG6bFtOyupOcN8CtwGbsRbiAzDGmGecmjILtDgo5SJSkmHdF7D4XUhNhmYvQuNnwOPGay/N2X6C/t9vIiXV8HKHyvRuGoanrviaI7JaHHYBVY0Ljz9pcVDKxVw4BnOHws7fILAidB4F5ZvfsPnWqBiem7aZ/dGXCCjgyaxnmlI6wDcHA+dPWV0+YztQwrmRlFJ5WuHS8OBk6DHD6kFMvgtm9IaLp9JtXiMkgPnPNeeBuiHEXE7ijg8W8fmS/bjwd9I8LzM9h8VALWAdkHD1fmPMXdkbLfO056CUC0u6AitGWz8ePtDqNaj3BLi5p9t8y9EYnp6ykWMxV6hZJoCpfRpQwMsj3bYqa7I6rJRuX9AYs9QJ2ZxCi4NSucDZ/dYWpQcWQ8la1halpeum29QYQ6+v17P0r2j8vT344pG6NK5QLIcD5316KqtSyjUYY+04N2coxJ2CiMeh9Wvgm/7aSz9vjOL56VsA65TXYZ2r6GS1E93qHtIXgfQeFKyzlQo5L2LWaHFQKpeJj7XOaFr3BRQIhHYjoMZD6V4bcTo2nt6TI9kadYEShXz4rnd9PeXVSbTnoJRyTSe2wMzn4VgklGtqndUUFJ6mmTGGwT9t5ccNUQD0aBDKsM5VdC4ii7Q4KKVcV2oqbJwEC4ZD4iVoPACaDQavtFuO7joRS//vN3Ig+hIAE3tF0Kpy8RwOnHfoTnBKKdfl5gYRj8HADVDjQeusps8awJ7ZaZpWKVmIRS+04K27bwfg8W8iGTJjq57ymg20OCilXEPBYnDPOHhsNngVhKndYGp3iDmSpmnPRuWY/mQjAH5Yf5R67yxg+7ELOZ04T9PioJRyLWUbQ7/l0PYtOLDE6kWsGA3JiX9rVj+sKDvebE/t0ADOxCXSZcwKnv1hE6mp2otwBp1zUEq5rpijMGcI7J4JQZWtCetyabe3X/pXNI9OXAeAu5uw5MUWlCmads5C/Z3OOSilcqeAMtBtCnSfBkmX4ZvO8Es/iIv+W7PmlYLYM6ID9cOKkpJqaPrhYubvTH+pDpU5WhyUUq4vvAM8vRaavgjbfoKxdWH9/1lnOjl4e7gz/clGDL/T2pGuz+RInvw2kriEZLtS52paHJRSuYNXAetq6qdWQYka1t4R/9cGjm/+W7NeTcL4vncDAObuOEW1N+YydV3aSW2VMS0OSqncJagSPPoHdP3SmpP4siX8OdjaqtShcYVi7H+3E73vsDYbGvrzNh7/Zr2e8noTbCkOIvKAiOwQkVQRifjHY0NFZJ+I7BGR9nbkU0q5OBHrmogB6yHiCVg3AcbWs4acHAXA3U14tUtVVg1pBcCi3aepMGw2R89dtjN5rmFXz2E70BVYdv2dIlIV6AbcDnQAxolI+uv6KqWUbwB0Hgl9F0OhUjDjCfj2Hjiz71qTUgG+7BnRgaolC12brP5z2wkbQ+cOthQHY8wuY8yedB66G/jBGJNgjDkI7APq52w6pVSuU6o29F4InUbCsU3weSNYNMLaSwJrsvrPQU15tk1FAJ6espFBP2zSYaYMuNqcQ2ng6HW3oxz3KaVUxtzcoX4fGBgJt98Lyz6CcQ1h7/xrTZ5tU4nfBzQB4LfNx6n82hxOXoi3K7FLy7biICILRGR7Oj93O+n4fUUkUkQio6Oj//0JSqn8wS8Yuk6wJq3dvWDK/TDtEbhgrehaIySAXW91oGKwHwnJqTR8byHfrjlsc2jXk23FwRjTxhhTLZ2f3zJ42jGgzHW3Qxz3pXf8CcaYCGNMRFBQkDOjK6XygrBm0G8ltH7d6j2MrQ+rxkBKEr5e7sx/vjkDWlYA4LVft9N3cqQOM13H1YaVfge6iYi3iIQBFbH2rlZKqZvn4QVNX4D+ayCsKcx7Fb5oDkfWAPBi+3AWvmDthDxv5ykavreQc5cSMzpivmHXqaz3ikgU0AiYJSJzAYwxO4DpwE5gDtDfGJNiR0alVB5SpBw8PA26fQ8JsTCxPfzWHy6d5bYgP7YOb0dgQS9OxSZQ5+35HIu5Yndi2+nCe0qp/CXxEiz9EFaPBW9/aPMm1H4EI8JT321kzo6TAMwe1JQqJV1mN+RsoQvvKaXUVV4Foe2b0G8FBFeFP56Bie2RU9sZ/0jda1dVd/zvcmZsiMq38xBaHJRS+VNwFeg1C+4ZD+cOWHMRc17h1bZleKVTZQBe+HELg3/aanNQe2hxUErlXyJQq7u1DEednrBmHIytR9/ArfzevzEAP26IImLEfE7F5q/rIbQ4KKVUgaJw5yfQewEUDIIfe1FjyRNseKo8oUULcCYukQbvLmTtgbN2J80xWhyUUuqqkAjosxg6fABH1xE4uTlL663hqTushRoemrCGz5fstzlkztDioJRS13P3gIb9rGU4qnRBlr7PywceY2prazXXD+bspu/kSC4n5u1NhLQ4KKVUevxLwP0T4ZFfAKHRyt5sqjKFEI8Y5u08RdXX53IgOs7ulNlGi4NSSmXktlbw9GpoOYwiRxawvMDLvFdqBe6k0GrUUnYej7U7YbbQ4qCUUv/GwxuaD4b+a5DQBnQ/N44lhd+ktuyl06fL+WPLcbsTOp0WB6WUyqyi5aHHT/DgZEK8LvOz93De9fiKV6cu590/d9mdzqm0OCil1M0Qgap3IwPWIY36091zKYu8X+Dcyq/pMynv7FOtxUEppW6Ftz+0fwd5chkFS4Yz0vML+uzvz4BPppCQnPvXC9XioJRSWVGiGj5953OuzcdUcjvOJzHP8P2IXkSdzN2bkGlxUEqprHJzo+gdT8CASCIDOvAYv+MxviGrZn4DuXSYSYuDUko5SUCxEtQfNIWvKo7nAgVpHDmIHaM6knL2oN3RbpoWB6WUciJ3N6F3j+6saT2Dcd6PU/biJlLH1ufKwvchOcHueJmmxUEppbLBo00r0vbxt+ju9Snzkmvhu/w9ksY2ggNL7Y6WKVoclFIqm1Qs7s+0l+7jJXmBRxNf5uzFyzD5LpjRBy6esjtehrQ4KKVUNirg5cHKl1vhGd6O5pfeY0xKV8yOX2FsPVj3JaS65mmvWhyUUiqbFSnoxbDOVXi0WWVGJd3PoKKfE1WgCvz5InzZCo5ttDtiGloclFIqB4QVK8izbSoSUbYIy84VonX0IE62G4e5eNIqELNegCsxdse8RouDUkrlkAJeHvz0VGMGtKxAQrKh4e8B/LfyFGjQDyInwtgI2DLNJa6N0OKglFI5rHv9UMb1qEPxQt7M+usSH7n14myPeRBQFn7pC5PuhOg9tmbU4qCUUjmsoLcHnaqXpHmlII6cu8xni/fzy4lAeGI+dPkETm6Dz5vAgjch8bItGSUvrCAYERFhIiMj7Y6hlFI3LTXVUGHYnxQv5EPpAF+GdqpM3cAUWPAGbJ4ChUOh04cQ3tHpry0iG4wxEek9pj0HpZSykZub0KdZeSoE+xF5+DxL90SDXxDcMw4emw1eBWFqN5j6MMQczbFc2nNQSikXUX34XAQI9PPmsSbl6NmoHKQkwZpxsOR9q1HzwdCwP3h4Zfn1tOeglFK5wHNtKtEiPJiYy4ks2eNY8tvdE5oMgv7rrP2sFwyHL5rCoRXZmkV7Dkop5WK6T1jDzhOx1AgpTNVShRjascr/HtwzB2a/BDFHoGZ3aPu2NQx1C7TnoJRSucidNUtRPqgge0/F8dXyg3/fejS8Azy9Fpq+ANt+gl/7ZUsG7TkopZSLGrdkHx/O2cPoh2ri6+lO80rB+Hq5/69B9F9gUiG48i0dP6Oeg8ctHVEppVS2K1XYF4Dnpm0B4O17qvFIw7L/axBUKdte25ZhJRF5QER2iEiqiERcd39bEdkgItsc/21lRz6llHIFd9cqxZIXWzB7UFMALlxOzLHXtqvnsB3oCnzxj/vPAHcaY46LSDVgLlA6p8MppZQrEBHKFSuIMQZ3N+GPLSfYH32JsGIFeaZ1xWx9bVt6DsaYXcaYNAuHGGM2GWOOO27uAHxFxDtn0ymllGsRETrcXoIrSSks2n2aj+f/RUJy9u4D4cpnK90HbDTGpLvpqoj0FZFIEYmMjo7O4WhKKZWzPutRh2WDWzKwVQUA4pNSs/X1sm1YSUQWACXSeWiYMea3f3nu7cAHQLsbtTHGTAAmgHW2UhaiKqVUruHjaZ2t9MmCvyjo5cE9tUtRIdjf6a+TbcXBGNPmVp4nIiHAL0BPY8x+56ZSSqncrVJxfwp4ufPt6sMkpxouXEni7XuqOf11XOpUVhEJAGYBQ4wxK+3Oo5RSrqZ+WFF2vtUBgIbvLiQxOXuGl+w6lfVeEYkCGgGzRGSu46EBQAXgdRHZ7PgJtiOjUkq5Onc3ISk1e4qDLT0HY8wvWENH/7x/BDAi5xMppVTu4+kuJKdkz5SrSw0rKaWUyryWlYMJKVIgW46txUEppXKpN+68PduO7crXOSillLKJFgellFJpaHFQSimVhhYHpZRSaWhxUEoplYYWB6WUUmlocVBKKZWGFgellFJpiDG5f7VrEYkGDmfhEMWwdqHL7/RzsOjnYNHPwZKXP4eyxpig9B7IE8Uhq0Qk0hgT8e8t8zb9HCz6OVj0c7Dk189Bh5WUUkqlocVBKaVUGlocLBPsDuAi9HOw6Odg0c/Bki8/B51zUEoplYb2HJRSSqWhxUEppVQa+bo4iEgHEdkjIvtEZIjdeewgImVEZLGI7BSRHSIyyO5MdhIRdxHZJCIz7c5iFxEJEJGfRGS3iOwSkUZ2Z7KDiDzn+DexXUSmioiP3ZlyUr4tDiLiDnwGdASqAt1FpKq9qWyRDLxgjKkKNAT659PP4apBwC67Q9jsv8AcY0xloCb58PMQkdLAM0CEMaYa4A50szdVzsq3xQGoD+wzxhwwxiQCPwB325wpxxljThhjNjp+v4j1h6C0vansISIhQGfgK7uz2EVECgPNgP8DMMYkGmNi7E1lGw/AV0Q8gALAcZvz5Kj8XBxKA0evux1FPv2jeJWIlANqA2vtTWKbT4DBQKrdQWwUBkQDXzuG174SkYJ2h8ppxphjwEjgCHACuGCMmWdvqpyVn4uDuo6I+AEzgGeNMbF258lpItIFOG2M2WB3Fpt5AHWAz40xtYFLQL6bjxORIlgjCWFAKaCgiPzH3lQ5Kz8Xh2NAmetuhzjuy3dExBOrMEwxxvxsdx6bNAHuEpFDWEOMrUTkO3sj2SIKiDLGXO09/oRVLPKbNsBBY0y0MSYJ+BlobHOmHJWfi8N6oKKIhImIF9Zk0+82Z8pxIiJY48u7jDEf253HLsaYocaYEGNMOaz/FxYZY/LVN0UAY8xJ4KiIhDvuag3stDGSXY4ADUWkgOPfSGvy2cS8h90B7GKMSRaRAcBcrDMRJhpjdtgcyw5NgEeAbSKy2XHfK8aYP23MpOw1EJji+NJ0AHjM5jw5zhizVkR+AjZindG3iXy2jIYun6GUUiqN/DyspJRS6ga0OCillEpDi4NSSqk0tDgopZRKQ4uDUkqpNLQ4KJclInG38JxPRKRZOvdXFpHNjiUhbnNOwtxPRJaISMS/tPlBRCrmVCblGrQ4qDxDRAKBhsaYZek8fA/wkzGmtjFm/3XPERHJ9f8OHIvDZZfPsdacUvlIrv9HofI+EWnh+IZ7dY+BKY6rVv/pPmBOOs/vBDwLPOXYu6KcYx+PycB2oIyIvCQi60Vkq4i8ed1zh4nIXyKywrGm/4uO+6994xaRYo5lN67uB/HRdcd68t/eg4jUE5FVIrJFRNaJiL+ILBORWtflWCEiNf/xvnqJyO8isghYKCJ+IrJQRDaKyDYRudvRrpxjX4YvHfsTzBMR338cy01EvhGREel8rsuBNtlcgJSL0eKgcovaWH/gqwLlsa7s/qcmQJqF8xxXe48HRhtjWjrurgiMM8bcDoQ7btcHagF1RaSZiNTFWkqjFtAJqJeJnE9greBZz9G+j4iE3eg9OK5CngYMMsbUxFrT5wrWkia9AESkEuBjjNmSzuvVAe43xjQH4oF7jTF1gJbAqOuKaEXgM8f7jcEqpFd5AFOAvcaYV9P5/FKBfVh7O6h8QouDyi3WGWOiHH+oNgPl0mlTEmu56cw4bIxZ4/i9neNnE9ZyCZWx/pg2BX4xxlx2rFSbmbW32gE9HUuRrAUCHce60XsIB04YY9YDGGNijTHJwI9AF8eiiI8D39zg9eYbY845fhfgXRHZCizAWoK+uOOxg8aYq8ujbODvn98XwHZjzDsZvK/TWKuTqnxCu4kqt0i47vcU0v9/9wqQ2a0cL133uwDvGWO+uL6BiDybwfOT+d+Xq+tfU4CBxpi5/zhWCzL3HgAwxlwWkflYy0Y/CNS9QdPr30cPIAioa4xJcgx1Xc32z9e+flhpFdBSREYZY+Jv8Do+WJ+vyie056Dykl1AhVt43lzgcceeFohIaREJBpYB94iIr4j4A3de95xD/O8P9v3/ONZTjm/8iEilf9ksZw9QUkTqOdr7Xze2/xXwKbDeGHM+E++jMNaeFEki0hIom4nngDWE9ScwPYN5hUpY8zMqn9DioPKSWUCLm32SY4ev74HVIrINaw8Df8f2qdOALcBsrGXerxqJVQQ2AcWuu/8rrCWuN4rIdqwhm4x6CInAQ8AYEdkCzMfxbd+x8VAs8HUm38oUIMLxHnoCuzP5PBzLtW8Cvv3n2VsiUhy44ljOW+UTuiqrylNEZAXQJTv2PRaR4UCcMWaks499g9crBSwBKjvmKWwhIs8BscaY/7Mrg8p52nNQec0LQKjdIbJKRHpiTWgPs7MwOMQAk2zOoHKY9hyUUkqloT0HpZRSaWhxUEoplYYWB6WUUmlocVBKKZWGFgellFJp/D+XKnf1VRlB+gAAAABJRU5ErkJggg==\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["## **Model Architecture**\n","\n","We now define the RNN model architecture with LSTM units used in this project that follows *Zaremba et al.* [[2](https://arxiv.org/abs/1409.2329)]\n","\n","Architecture overview:\n","\n","\n","```\n","Architecture(\n","  (emb): Embedding(vocab_size, custom_emb_dim)\n","  (rnn): LSTM(custom_emb_dim, custom_hidden_size, num_layers= custom_nLayers)\n","  (decoder): Linear(in_features=custom_hidden_size, out_features=vocab_size, bias=True)\n",")\n","```\n","\n","This is the base for all the NNs used in this project. Depending on the version we are dealing with dropout will be used in different ways and places. \n","\n","\n","\n"],"metadata":{"id":"Ro2m9d43_wNB"}},{"cell_type":"markdown","source":["In this first model implementation the dropout variable is unique and it will just store a probability of units drop. However, in this case the dropout will be applied on non-recurrent connections of the LSTM (as well as on generated embeddings and final output) in a naive manner.\n","\n","<img src=\"https://i.ibb.co/h8yrcHV/dropouts-Copy.png\" alt=\"dropouts-Copy\" border=\"0\" width = 400>\n","\n","_Image taken from Gal et al. paper_ [[3](http://arxiv.org/abs/1512.05287)]\n","\n"],"metadata":{"id":"8m-fELtsr-9d"}},{"cell_type":"code","source":["class Model(nn.Module):\n","\n","    def __init__(self, vocab_size, emb_dim, nhid, nlayers, winit, dropout=0.5): \n","        super(Model, self).__init__()\n","        \n","        self.drop = nn.Dropout(dropout)\n","        self.emb = nn.Embedding(vocab_size, emb_dim) \n","        self.rnn = nn.LSTM(emb_dim, nhid, nlayers, dropout=dropout) \n","        self.decoder = nn.Linear(nhid, vocab_size)\n","        \n","        self.winit = winit\n","        self.nhid = nhid\n","        self.nlayers = nlayers\n","        \n","        self.init_weights()\n","        \n","    def init_weights(self):\n","        # Paper 4.1 ~ units of the layers are initialized uniformly in [-winit, winit] \n","        self.emb.weight.data.uniform_(-self.winit , self.winit )\n","        self.decoder.bias.data.fill_(0)\n","        self.decoder.weight.data.uniform_(-self.winit , self.winit )\n","\n","    def init_hidden(self, batch_size):\n","        # Paper 4.1 ~ initialize the hidden states to zero \n","        weight = next(self.parameters()).data\n","        return weight.new_zeros(self.nlayers, batch_size, self.nhid), weight.new_zeros(self.nlayers, batch_size, self.nhid)\n","\n","    def forward(self, input, hidden):\n","        emb = self.drop(self.emb(input))\n","        output, hidden = self.rnn(emb, hidden)\n","        output = self.drop(output)\n","        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n","        return decoded, hidden"],"metadata":{"id":"DzJt7r9jA4OD","executionInfo":{"status":"ok","timestamp":1658506331204,"user_tz":-120,"elapsed":279,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}}},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":["This is the second model implementation where I follow the idea of _Gal et al._ [[3](http://arxiv.org/abs/1512.05287)]\n","\n","<img src=\"https://i.ibb.co/4N1rTQn/dropouts-Copy-Copy.png\" alt=\"dropouts-Copy-Copy\" border=\"0\" width = 400>\n","\n","_Image taken from Gal et al. paper_ [[3](http://arxiv.org/abs/1512.05287)]\n","\n","In this case I tried to replicate exactly what we see in the picture. \n","\n","```\n","self.dropout_embedding = LockedDropout(dropout_embedding) # blue\n","self.dropout_rnnhid1 = LockedDropout(dropout_rnnhid) # orange\n","self.dropout_rnnhid2 = LockedDropout(dropout_rnnhid) # dark red\n","self.dropout_rnnlay = LockedDropout(dropout_rnnlay) # green\n","self.dropout_finalout = LockedDropout(dropout_finalout) # bright red\n","```\n","\n"],"metadata":{"id":"wvLHkVQvtQTu"}},{"cell_type":"code","source":["class VarModel(nn.Module):\n","\n","    def __init__(self, vocab_size, emb_dim, nhid, nlayers, winit,\n","                 dropout_embedding=0.5,\n","                 dropout_rnnhid=0.5,\n","                 dropout_rnnlay=0.5,\n","                 dropout_finalout=0.5\n","                 ): \n","\n","\n","        super(VarModel, self).__init__()\n","\n","        # (PyTorch-NLP) 'LockedDropout' allows to create a dropout mask\n","        self.dropout_embedding = LockedDropout(dropout_embedding)\n","        self.dropout_rnnhid1 = LockedDropout(dropout_rnnhid)\n","        self.dropout_rnnhid2 = LockedDropout(dropout_rnnhid)\n","        self.dropout_rnnlay = LockedDropout(dropout_rnnlay)\n","        self.dropout_finalout = LockedDropout(dropout_finalout)\n","\n","\n","        self.emb = nn.Embedding(vocab_size, emb_dim)\n","        self.rnn1 = nn.LSTM(emb_dim, nhid, 1, dropout=0) \n","        self.rnn2 = nn.LSTM(emb_dim, nhid, 1, dropout=0) \n","        self.decoder = nn.Linear(nhid, vocab_size)\n","        \n","        self.decoder.weight = self.emb.weight\n","        \n","        self.winit = winit\n","        self.nhid = nhid\n","        self.nlayers = nlayers\n","        \n","        self.init_weights()\n","        \n","    def init_weights(self):\n","        self.emb.weight.data.uniform_(-self.winit , self.winit )\n","        self.decoder.bias.data.fill_(0)\n","        self.decoder.weight.data.uniform_(-self.winit , self.winit )\n","\n","    def init_hidden(self, batch_size):\n","        weight = next(self.parameters()).data\n","        return [(weight.new_zeros(1, batch_size, self.nhid, device = \"cuda:0\"),\n","                weight.new_zeros(1, batch_size, self.nhid, device = \"cuda:0\"))\n","                for l in range(self.nlayers)]\n","\n","    def forward(self, input, hidden):\n","        emb = self.dropout_embedding(self.emb(input))\n","        new_hidden = []\n","        out1, h1 = self.rnn1(emb, (self.dropout_rnnhid1(hidden[0][0]), self.dropout_rnnhid1(hidden[0][1])))\n","        out1 = self.dropout_rnnlay(out1)\n","        out2, h2 = self.rnn2(out1, (self.dropout_rnnhid1(hidden[1][0]), self.dropout_rnnhid1(hidden[1][1])))\n","        hidden = [h1,h2]\n","        output = self.dropout_finalout(out2)\n","        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n","        return decoded, hidden"],"metadata":{"id":"Aax9n3_tv-Fb","executionInfo":{"status":"ok","timestamp":1658507357997,"user_tz":-120,"elapsed":336,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["def repackage_hidden(h):\n","    if isinstance(h, torch.Tensor):\n","        return h.detach()\n","    else:\n","        return tuple(repackage_hidden(v) for v in h)"],"metadata":{"id":"irxutuPPEUXe","executionInfo":{"status":"ok","timestamp":1658501649585,"user_tz":-120,"elapsed":2,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## **Train and Test steps**"],"metadata":{"id":"LB6OzFUSEm2u"}},{"cell_type":"code","source":["def test_step(data_tensor, source_slices, target_slices):\n","    model.eval()\n","    total_loss = 0\n","    tot_samples = 0\n","\n","    with torch.no_grad():\n","        hidden = model.init_hidden(batch_size)\n","        \n","        for source_slice, target_slice in zip(source_slices, target_slices):\n","            data = torch.stack([data_tensor[i] for i in source_slice], dim = 1)\n","            targets = torch.stack([data_tensor[i] for i in target_slice], dim = 1).view(-1)\n","            \n","            output, hidden = model(data, hidden)\n","\n","            loss = criterion(output, targets) * output.size(0)\n","            total_loss += loss\n","            tot_samples += output.size(0)\n","\n","        avg_loss = total_loss/tot_samples\n","        avg_ppl = math.exp(avg_loss)\n","    return avg_loss, avg_ppl"],"metadata":{"id":"ITzNKR7cFLkA","executionInfo":{"status":"ok","timestamp":1658501650551,"user_tz":-120,"elapsed":8,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["def train_step():\n","    model.train()\n","    hidden = model.init_hidden(batch_size)\n","    \n","    batch = 0\n","    if epoch >= epoch_decay_lr:\n","        scheduler.step() \n","\n","    \n","    for source_slice, target_slice in zip(train_source_sampler, train_target_sampler):\n","            \n","\n","        data = torch.stack([train_data[i] for i in source_slice], dim =1)\n","        targets = torch.stack([train_data[i] for i in target_slice], dim = 1).view(-1)\n","\n","        hidden = repackage_hidden(hidden)   \n","\n","        optimizer.zero_grad()\n","\n","        output, hidden = model(data, hidden)\n","\n","        loss = criterion(output, targets)\n","        loss.backward()\n","\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n","        optimizer.step()\n","        \n","        if batch%report_iterations == 0:\n","            print('| epoch {:d} | {:d}/{:d} batches | lr {:.3f} | loss {:.3f} |'.format(\n","                epoch+1, batch, len(train_source_sampler), scheduler.get_last_lr()[0], loss.item()\n","            ), file = f)\n","\n","        \n","        batch += 1\n"],"metadata":{"id":"mCTppzIWFN0M","executionInfo":{"status":"ok","timestamp":1658501654223,"user_tz":-120,"elapsed":260,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["# Use the CUDA variable below to decide if training on GPU or CPU\n","# Note that all my experiments ran on GPU\n","\n","cuda = True\n","\n","if torch.cuda.is_available() and cuda:\n","    print(\"Model will be training on the GPU.\\n\")\n","    pass\n","    \n","else:\n","    cuda = False\n","    print(\"Model will be training on the CPU.\\n\")\n","\n","torch.cuda.manual_seed(5) if cuda else torch.manual_seed(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTj1YbSyEiR3","executionInfo":{"status":"ok","timestamp":1658501657793,"user_tz":-120,"elapsed":8,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}},"outputId":"85b72427-8d02-451e-967c-c81f4d1b7e7d"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Model will be training on the GPU.\n","\n"]}]},{"cell_type":"code","source":["# decide batch size and sequence length to feed to the model\n","\n","seq_len = 35 \n","batch_size = 20 \n","\n","if cuda:\n","    print(\"Loading data on GPU...\")\n","    train_data = encoder.batch_encode(train).cuda()\n","    val_data = encoder.batch_encode(val).cuda()\n","    test_data = encoder.batch_encode(test).cuda()\n","else:\n","    print(\"Loading data on CPU...\")\n","    train_data = encoder.batch_encode(train)\n","    val_data = encoder.batch_encode(val)\n","    test_data = encoder.batch_encode(test)\n","\n","# (PyTorch-NLP) 'BPTTBatchSampler' samples sequentially a batch of source and target slices of size bptt_length.\n","# Typically, such a sampler, is used for language modeling training with backpropagation through time (BPTT).\n","\n","train_source_sampler, val_source_sampler, test_source_sampler = tuple(\n","    [BPTTBatchSampler(data = d, bptt_length = seq_len, batch_size = batch_size, \n","                      drop_last = True, type_ = 'source') for d in (train, val, test)])\n","\n","train_target_sampler, val_target_sampler, test_target_sampler = tuple(\n","    [BPTTBatchSampler(data = d, bptt_length = seq_len, batch_size = batch_size, \n","                      drop_last = True, type_ = 'target') for d in (train, val, test)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"69kcdvAwFtXL","executionInfo":{"status":"ok","timestamp":1658507466694,"user_tz":-120,"elapsed":9773,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}},"outputId":"18763255-85a3-4b00-a6bd-7aee473ce2af"},"execution_count":56,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data on GPU...\n"]}]},{"cell_type":"markdown","source":["Here decide if:\n","- you what to train the model(s) from scratch or just load them\n","- If training from scratch is chosen:\n","  - how many times to train the chosen model\n","  - which type of model to train"],"metadata":{"id":"q7ga4Ajgv6nD"}},{"cell_type":"code","source":["# train = True --> train from scratch the model\n","# train = False --> load the model \n","\n","train = False\n","nruns = 1\n","ppls = np.zeros(nruns)\n","\n","# model_type:\n","# 0 --> non-regularized LSTM\n","# 1 --> medium regularized LSTM\n","# 2 --> large regularized LSTM\n","# 3 --> variational LSTM\n","\n","model_type = 3\n","\n","ntokens = encoder.vocab_size\n","\n","if model_type == 0:\n","  beg = \"noREG\"\n","\n","  best_of_bests = 0\n","  \n","  emsize = 200 \n","  nhid = 200 \n","  nlayers = 2 \n","  dropout = 0.0 \n","  winit = 0.1 \n","  max_norm = 5\n","  factor = 0.5\n","  init_lr = 1 \n","  tot_epochs = 13 \n","  epoch_decay_lr = 4 \n","  report_iterations = 500 \n","\n","elif model_type == 1:\n","  beg = \"medREG\"\n","\n","  best_of_bests = 2\n","\n","  emsize = 650 \n","  nhid = 650 \n","  nlayers = 2\n","  dropout = 0.5 \n","  winit = 0.05 \n","  max_norm = 5 \n","  factor = 0.83333\n","  init_lr = 1 \n","  tot_epochs = 39 \n","  epoch_decay_lr = 6 \n","  report_iterations = 500 \n","\n","elif model_type == 2:\n","  beg = \"largeREG\"\n","\n","  best_of_bests = 0\n","  \n","  emsize = 1500 \n","  nhid = 1500 \n","  nlayers = 2 \n","  dropout = 0.65 \n","  winit = 0.04 \n","  max_norm = 10\n","  factor = 0.8695652\n","  init_lr = 1 \n","  tot_epochs = 55 \n","  epoch_decay_lr = 14\n","  report_iterations = 500\n","\n","else:\n","  beg = \"varREG\"\n","\n","  best_of_bests = 3\n","\n","  emsize = 650 \n","  nhid = 650 \n","  nlayers = 2\n","  dropout = 0.5\n","  winit = 0.05 \n","  max_norm = 5 \n","  factor = 0.83333\n","  init_lr = 1 \n","  tot_epochs = 39 \n","  epoch_decay_lr = 6\n","  report_iterations = 500\n","\n","  dropout_embedding=0.5 \n","  dropout_rnnhid=0.3 \n","  dropout_rnnlay=0.4 \n","  dropout_finalout=0.5\n","\n","# initialize the model\n","if model_type != 3:\n","  model = Model(ntokens, emsize, nhid, nlayers, winit, dropout)\n","else:\n","  model = VarModel(ntokens, emsize, nhid, nlayers, winit, dropout_embedding, dropout_rnnhid, dropout_rnnlay, dropout_finalout)\n","\n","if cuda:\n","  model.cuda()\n","\n","\n","# initialize the optimizer, scheduler and criterion for the loss\n","optimizer = torch.optim.SGD(model.parameters(), lr= 1, momentum=0.8)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 1, gamma = factor) \n","criterion = nn.CrossEntropyLoss()"],"metadata":{"id":"G9Luioe4GUXB","executionInfo":{"status":"ok","timestamp":1658503871459,"user_tz":-120,"elapsed":454,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["if train:\n","  with open(beg+'out.txt', 'w') as f: \n","\n","      print(\"PARAMETERS\", file = f)\n","\n","      print(\"\\nntokens = {:d}\\nemsize = {:d}\\nnhid = {:d}\\nnlayers = {:d}\\ndropout = {:.3f}\\nwinit = {:.3f}\\nmax_norm = {:d}\\nfactor = {:.3f}\\ninit_lr = {:d}\\ntot_epochs = {:d}\\nepoch_decay_lr = {:d}\\nreport_iterations = {:d}\".format(ntokens, emsize, nhid, nlayers,\n","                                                  dropout, winit, max_norm, factor,\n","                                                  init_lr, tot_epochs, epoch_decay_lr,\n","                                                  report_iterations), file = f)      \n","      print(model, file = f)\n","\n","      for run in range(nruns):\n","\n","          print(\"\\n\\nRUN {:d}\\n\\n\".format(run+1), file = f)                   \n","          best_val_loss = []\n","          stored_loss = math.inf\n","\n","          path_save_model = \"./trained_models/\"+beg\n","          \n","          for epoch in range (0, tot_epochs):\n","              \n","              print(\"\\n##################################################################################\\n\", file = f)\n","              print(\"EPOCH: \", epoch+1, file = f)\n","              print(\"\\nTrain ------------\\n\", file = f)\n","              train_step()\n","              print(\"\\n\\nValidation -------\\n\", file = f)\n","              val_avg_loss, val_avg_ppl = test_step(val_data, val_source_sampler, val_target_sampler)\n","              print(\"\\nAvg loss: {:.3f} | Avg ppl: {:.3f}\\n\".format(val_avg_loss, val_avg_ppl), file = f)\n","              if val_avg_loss < stored_loss:\n","                  # torch.save(model.state_dict(), path_save_model+str(run)+\".pt\")\n","                  torch.save(model.state_dict(), path_save_model+str(4)+\".pt\")\n","                  print('\\nSaving model (new best validation)', file = f)\n","                  stored_loss = val_avg_loss\n","\n","\n","          print(\"\\n\\n\\n\\n\\nLoading the best model...\\n\", file = f)\n","          # model.load_state_dict(torch.load(path_save_model+str(run)+\".pt\"))\n","          model.load_state_dict(torch.load(path_save_model+str(4)+\".pt\"))\n","          \n","        \n","          print(\"*\"*89, file = f)\n","          print(\"*\"*89, file = f)\n","          print(\"\\nTESTING ----------\", file = f)\n","          test_avg_loss, test_avg_ppl = test_step(test_data, test_source_sampler, test_target_sampler)\n","          print(\"Avg loss: {:.3f} | Avg ppl: {:.3f}\\n\".format(test_avg_loss, test_avg_ppl), file = f)\n","          print(\"*\"*89, file = f)\n","          print(\"*\"*89, file = f)\n","\n","          ppls[run] = test_avg_ppl\n","\n","      best_of_bests = ppls.argmin()\n","      print(\"\\n\\nFinal average ppl over {:d} runs is {:.3f} with a standard deviation of {:.3f}\".format(nruns, np.mean(ppls), np.std(ppls)), file = f)\n","\n","      print(\"\\nBest final model was the one in run \", best_of_bests, file = f)\n","\n","      f.close()\n","\n","else:\n","  path_load_model = \"./trained_models/\"+beg+str(best_of_bests)+\".pt\"\n","\n","  print(\"\\nLoading the best model...\\n\")\n","  model.load_state_dict(torch.load(path_load_model))\n","\n","  print(\"\\nTESTING ----------\")\n","  test_avg_loss, test_avg_ppl = test_step(test_data, test_source_sampler, test_target_sampler)\n","  print(\"Avg loss: {:.3f} | Avg ppl: {:.3f}\\n\".format(test_avg_loss, test_avg_ppl))"],"metadata":{"id":"UJMK2x9d780A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Predict**"],"metadata":{"id":"ObKlCjWiwg1o"}},{"cell_type":"code","source":["# given a initial sentence and a number of words to generate this function will use\n","# the last loaded model to predict the words\n","def predict_word(start_text, nwords2gen):\n","    start_text_processed = []\n","    for word in start_text:\n","      if word in encoder.vocab:\n","        start_text_processed.append(word)\n","      else:\n","        start_text_processed.append(\"<unk>\")    \n","    \n","    new_words = torch.cuda.LongTensor()\n","    model.eval()\n","    with torch.no_grad():\n","        source = encoder.batch_encode(start_text_processed).cuda()\n","        source = torch.reshape(source, (list(source.size())[0], 1))\n","\n","        hidden = model.init_hidden(1)\n","        soft = nn.Softmax(dim = 1)\n","        for i in range(nwords2gen):\n","          data4model = source\n","\n","          output, hidden = model(data4model, hidden)\n","\n","          next_word_probs = soft(output)[-1]\n","          \n","          get_word_idx = torch.multinomial(next_word_probs, 1)\n","          if get_word_idx == encoder.encode(\"<unk>\") or get_word_idx == encoder.encode(\"N\") or get_word_idx == encoder.encode(\"$\"):\n","            next_word_probs[get_word_idx] = 0.\n","            get_word_idx = torch.multinomial(next_word_probs, 1)\n","\n","          new_words = torch.cat((new_words, get_word_idx))\n","          get_word_idx = get_word_idx[-1:,None]\n","      \n","          source = torch.cat((source, get_word_idx), dim = 0)\n","\n","          to_print = []\n","          for w in start_text+encoder.batch_decode(new_words):\n","            if w == \"</s>\":\n","              to_print.append(\".\")\n","            else:\n","              to_print.append(w)\n","          print(\" \".join(to_print))        "],"metadata":{"id":"qaJ5IED9QzAZ","executionInfo":{"status":"ok","timestamp":1658501730765,"user_tz":-120,"elapsed":285,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# given a initial sentence and a number of sentences to generate this function will use\n","# the last loaded model to predict them\n","def predict_sent(start_text, nsent2gen):\n","    current_sent = 1\n","    start_text_processed = []\n","    for word in start_text:\n","      if word.lower() in encoder.vocab:\n","        start_text_processed.append(word.lower())\n","      else:\n","        start_text_processed.append(\"<unk>\")    \n","    \n","    new_words = torch.cuda.LongTensor()\n","\n","    stop_anyway = 0\n","    flag = False\n","    model.eval()\n","    with torch.no_grad():\n","\n","        source = encoder.batch_encode(start_text_processed).cuda()\n","        source = torch.reshape(source, (list(source.size())[0], 1))\n","\n","        hidden = model.init_hidden(1)\n","        soft = nn.Softmax(dim = 1)\n","\n","        while current_sent <= nsent2gen:\n","          if stop_anyway < 30:\n","            data4model = source\n","            output, hidden = model(data4model, hidden)\n","\n","            next_word_probs = soft(output)[-1]\n","            \n","            get_word_idx = torch.multinomial(next_word_probs, 1)\n","            while get_word_idx == encoder.encode(\"<unk>\") or get_word_idx == encoder.encode(\"N\") or get_word_idx == encoder.encode(\"$\"):\n","              next_word_probs[get_word_idx] = 0.\n","              get_word_idx = torch.multinomial(next_word_probs, 1)\n","\n","            if get_word_idx == encoder.encode(\"</s>\"):\n","              current_sent +=1\n","              stop_anyway = 0\n","\n","\n","            new_words = torch.cat((new_words, get_word_idx))\n","            get_word_idx = get_word_idx[-1:,None]\n","        \n","            source = torch.cat((source, get_word_idx), dim = 0)\n","            stop_anyway +=1\n","          else:\n","            # uncomment below if you want to see the generated sentences\n","            # print(\"early stop\\n\")\n","            flag = True\n","            break\n","\n","        to_print = []\n","        for w in start_text+encoder.batch_decode(new_words):\n","          if w == \"</s>\":\n","            to_print.append(\".\\n\")\n","              \n","          else:\n","            to_print.append(w)\n","        # uncomment below if you want to see the generated sentences\n","        # print(\" \".join(to_print))\n","\n","        return to_print, flag"],"metadata":{"id":"ZG6WVHEWQzwI","executionInfo":{"status":"ok","timestamp":1658507764544,"user_tz":-120,"elapsed":383,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["how_many_next_words = 10\n","plain_txt = \"The meaning of life is\"\n","\n","split_text = plain_txt.split()\n","predict_word(split_text, how_many_next_words)"],"metadata":{"id":"QEztgDzGQ2pS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["nsent2gen =  2\n","plain_txt = \"The meaning of life is\"\n","\n","split_text = plain_txt.split()\n","res,_ = predict_sent(split_text, nsent2gen)"],"metadata":{"id":"tQTkC79SQ8at","executionInfo":{"status":"ok","timestamp":1658507784238,"user_tz":-120,"elapsed":449,"user":{"displayName":"Lorenzo C","userId":"06860813363541725217"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["lens = np.empty(0)\n","stops = np.empty(0)\n","for i in range(100):\n","  nsent2gen =  1\n","  plain_txt = \"The meaning of life is\"\n","\n","  split_text = plain_txt.split()\n","\n","  sents_list, flag = predict_sent(split_text, nsent2gen)\n","  \n","  if not flag:\n","    avg_len = len(sents_list)/nsent2gen\n","    lens = np.append(lens, avg_len)\n","  else:\n","    stops = np.append(stops, sents_list.count(\".\\n\"))\n","\n","print(\"Among 100 trials of generating {:d} sentences, {:d} succeeded to do it.\".format(nsent2gen, len(lens)))\n","print(\"Considering the successful trials, the average number of words per sentence is {:.3f}\".format(np.mean(lens)))"],"metadata":{"id":"sgflapFp9vNJ"},"execution_count":null,"outputs":[]}]}